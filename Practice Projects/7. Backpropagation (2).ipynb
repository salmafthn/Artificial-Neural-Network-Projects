{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvonXDMsQP1k"
      },
      "source": [
        "# Bab 8 Backpropagation (2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHySaU_QQPg1"
      },
      "source": [
        "## Praktikum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hihqFCY_ctZ3"
      },
      "source": [
        "### a) Fungsi *Training* Backpropagation\n",
        "\n",
        "Tulis kode ke dalam *cell* di bawah ini:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "fkwoTrDc2X78"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sig(X):\n",
        "  return [1/(1 + np.exp(-x)) for x in X]\n",
        "\n",
        "def sigd(X):\n",
        "  output = []\n",
        "\n",
        "  for i, x in enumerate(X):\n",
        "    s = sig([x])[0]\n",
        "\n",
        "    output.append(s * (1 - s))\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "VAaj-gbn4A0k"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTlk5igwcvc5"
      },
      "source": [
        "def bp_fit(X, target, layer_conf, max_epoch, max_error = .1, learn_rate = .1, print_per_epoch=100):\n",
        "    np.random.seed(1)\n",
        "    nin = [np.empty(i) for i in layer_conf]\n",
        "    n = [np.empty(j + 1) if i < len(layer_conf) - 1 else np.empty(j) for i, j in enumerate(layer_conf)]\n",
        "    # w = np.array([np.random.rand(layer_conf[i] + 1, layer_conf[i + 1]) for i in range(len(layer_conf) - 1)])\n",
        "    w = [np.random.rand(layer_conf[i] + 1, layer_conf[i + 1]) for i in range(len(layer_conf) - 1)]\n",
        "    dw = [np.empty((layer_conf[i] + 1, layer_conf[i + 1])) for i in range(len(layer_conf) - 1)]\n",
        "    d = [np.empty(s) for s in layer_conf[1:]]\n",
        "    din = [np.empty(s) for s in layer_conf[1:-1]]\n",
        "    epoch = 0\n",
        "    mse = 1\n",
        "\n",
        "    for i in range(0, len(n)-1):\n",
        "      n[i][-1] = 1\n",
        "\n",
        "      while (max_epoch == -1 or epoch < max_epoch) and mse > max_error:\n",
        "        epoch += 1\n",
        "        mse = 0\n",
        "\n",
        "        for r in range(len(X)):\n",
        "          n[0][:-1] = X[r]\n",
        "\n",
        "          for L in range(1, len(layer_conf)):\n",
        "            nin[L] = np.dot(n[L-1], w[L-1])\n",
        "            n[L][:len(nin[L])] = sig(nin[L])\n",
        "\n",
        "          e = target[r] - n[-1]\n",
        "          mse += sum(e ** 2)\n",
        "          d[-1] = e * sigd(nin[-1])\n",
        "          dw[-1] = learn_rate * d[-1] * n[-2].reshape((-1, 1))\n",
        "\n",
        "          for L in range(len(layer_conf) - 1, 1, -1):\n",
        "            din[L-2] = np.dot(d[L-1], np.transpose(w[L-1][:-1]))\n",
        "            d[L-2] = din[L-2] * np.array(sigd(nin[L-1]))\n",
        "            dw[L-2] = (learn_rate * d[L-2]) * n[L-2].reshape((-1, 1))\n",
        "\n",
        "          for i in range(len(w)):\n",
        "            w[i] += dw[i]\n",
        "\n",
        "        mse /= len(X)\n",
        "\n",
        "        if print_per_epoch > -1 and epoch % print_per_epoch == 0:\n",
        "          print(f'Epoch: {epoch}, MSE: {mse}')\n",
        "\n",
        "      return w, epoch, mse"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJA_9btdc3ED"
      },
      "source": [
        "### b) Fungsi *Testing* Backpropagation\n",
        "\n",
        "Tulis kode ke dalam *cell* di bawah ini:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bp_predict(X, w):\n",
        "  n = [np.empty(len(i)) for i in w]\n",
        "  nin = [np.empty(len(i[0])) for i in w]\n",
        "  predict = []\n",
        "\n",
        "  n.append(np.empty(len(w[-1][0])))\n",
        "\n",
        "  for x in X:\n",
        "    n[0][:-1] = x\n",
        "\n",
        "    for L in range(0, len(w)):\n",
        "      nin[L] = np.dot(n[L], w[L])\n",
        "      n[L+1][:len(nin[L])] = sig(nin[L])\n",
        "\n",
        "    predict.append(n[-1].copy())\n",
        "\n",
        "  return predict"
      ],
      "metadata": {
        "id": "s-FXRalE08FT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZxy_M5Jc-ko"
      },
      "source": [
        "### c) Percobaan Klasifikasi Dataset Iris\n",
        "\n",
        "![Iris Dataset](https://www.spataru.at/images/blog/iris-dataset-svm/iris_types.jpg)\n",
        "\n",
        "Tulis kode ke dalam *cell* di bawah ini:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def onehot_enc(lbl, min_val=0):\n",
        "  mi = min(lbl)\n",
        "  enc = np.full((len(lbl), max(lbl) - mi + 1), min_val, np.int8)\n",
        "\n",
        "  for i, x in enumerate(lbl):\n",
        "    enc[i, x - mi] = 1\n",
        "\n",
        "  return enc\n",
        "\n",
        "def onehot_dec(enc, mi=0):\n",
        "  return [np.argmax(e) + mi for e in enc]"
      ],
      "metadata": {
        "id": "diSgX-El3B1p"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw1L_Q3JdHk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f515edaf-3d09-48e0-b7e1-354216746f35"
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "X = minmax_scale(iris.data)\n",
        "Y = onehot_enc(iris.target)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.3, random_state=1)\n",
        "w, ep, mse = bp_fit(X_train, y_train, layer_conf = (4,3,3), learn_rate = .1, max_epoch = 1000, max_error = .1, print_per_epoch = 25)\n",
        "\n",
        "print(f'Epoch: {ep}, MSE: {mse}')\n",
        "\n",
        "predict = bp_predict(X_test, w)\n",
        "predict = onehot_dec(predict)\n",
        "y_test = onehot_dec(y_test)\n",
        "accuracy = accuracy_score(predict, y_test)\n",
        "\n",
        "print('Output:', predict)\n",
        "print('Target:', y_test)\n",
        "print('Accuracy:', accuracy)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25, MSE: 0.3833166779443107\n",
            "Epoch: 50, MSE: 0.301396185088815\n",
            "Epoch: 75, MSE: 0.26148932074548786\n",
            "Epoch: 100, MSE: 0.19740347109913006\n",
            "Epoch: 125, MSE: 0.13591678154244755\n",
            "Epoch: 150, MSE: 0.1005247355667754\n",
            "Epoch: 151, MSE: 0.09953734654801856\n",
            "Output: [0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1, 2, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2, 1]\n",
            "Target: [0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2, 1]\n",
            "Accuracy: 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisis\n",
        "1. Lakukan klasifikasi dengan menggunakan dataset Iris seperti di atas.\n",
        "Ubahlah beberapa pengaturan sebagai berikut:\n",
        "* Rasio data latih 70% dan data uji 30%\n",
        "* Hidden neuron = 2\n",
        "* Max epoch = 100\n",
        "* Learning rate = 0,1\n",
        "* Max error = 0,5\n",
        "\n",
        " pengujian (testing) menggunakan data latih dan data uji. Bandingkan nilai akurasi yang didapatkan. Fenomena apa yang terjadi pada pengujian ini? Mengapa hal tersebut terjadi?\n",
        "\n",
        "2. Lakukan klasifikasi dengan menggunakan dataset Iris seperti di atas.\n",
        "Ubahlah beberapa pengaturan sebagai berikut:\n",
        "* Rasio data latih 70% dan data uji 30%\n",
        "* Hidden neuron = 25\n",
        "* Max epoch = 10000\n",
        "* Learning rate = 0,1\n",
        "* Max error = 0,01\n",
        "\n",
        "  Lakukan pengujian (testing) menggunakan data latih dan data uji. Bandingkan nilai akurasi yang didapatkan. Fenomena apa yang terjadi pada pengujian ini? Mengapa hal tersebut terjadi?\n",
        "\n",
        "3. Ubahlah parameter berikut agar mendapatkan akurasi tertinggi saat\n",
        "melakukan testing menggunakan data uji :\n",
        "* Hidden neuron\n",
        "* Max epoch\n",
        "* Max error\n",
        "\n",
        "  Berapakah nilai akurasi tertinggi yang dapat Anda peroleh? Berapakah nilai masing-masing parameter tersebut?\n",
        "\n"
      ],
      "metadata": {
        "id": "G0R_G7X64mmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "JAWABAN\n"
      ],
      "metadata": {
        "id": "j1NragWq5_P3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.3, random_state=1)\n",
        "w, ep, mse = bp_fit(X_train, y_train, layer_conf = (4,2,3), learn_rate = .1, max_epoch = 100, max_error = .5, print_per_epoch = 25)\n",
        "\n",
        "print(f'Epoch: {ep}, MSE: {mse}')\n",
        "\n",
        "predict1 = bp_predict(X_test, w)\n",
        "predict1 = onehot_dec(predict1)\n",
        "y_test = onehot_dec(y_test)\n",
        "accuracy = accuracy_score(predict1, y_test)\n",
        "\n",
        "print('Output:', predict1)\n",
        "print('Target:', y_test)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKTryidz6KNQ",
        "outputId": "df97d041-28a6-4ac7-a637-e2329f4b1724"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25, MSE: 0.6023662849933146\n",
            "Epoch: 33, MSE: 0.48792259684397216\n",
            "Output: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "Target: [0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2, 1]\n",
            "Accuracy: 0.28888888888888886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.3, random_state=1)\n",
        "w, ep, mse = bp_fit(X_train, y_train, layer_conf = (4,25,3), learn_rate = .1, max_epoch = 10000, max_error = .01, print_per_epoch = 25)\n",
        "\n",
        "print(f'Epoch: {ep}, MSE: {mse}')\n",
        "\n",
        "predict2 = bp_predict(X_test, w)\n",
        "predict2 = onehot_dec(predict2)\n",
        "y_test = onehot_dec(y_test)\n",
        "accuracy = accuracy_score(predict2, y_test)\n",
        "\n",
        "print('Output:', predict2)\n",
        "print('Target:', y_test)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmi2KFQ86wSY",
        "outputId": "b7fd78bc-b43d-4152-9e94-14bf1854d58a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25, MSE: 1.9993202764736877\n",
            "Epoch: 50, MSE: 1.9985480410601613\n",
            "Epoch: 75, MSE: 1.558898734035213\n",
            "Epoch: 100, MSE: 0.9724997905330577\n",
            "Epoch: 125, MSE: 0.3168162131601929\n",
            "Epoch: 150, MSE: 0.24245559937220204\n",
            "Epoch: 175, MSE: 0.1854405746593738\n",
            "Epoch: 200, MSE: 0.13987973956674984\n",
            "Epoch: 225, MSE: 0.11042567912241297\n",
            "Epoch: 250, MSE: 0.09151661694263978\n",
            "Epoch: 275, MSE: 0.07920661111748672\n",
            "Epoch: 300, MSE: 0.07097830670337435\n",
            "Epoch: 325, MSE: 0.06525694176677267\n",
            "Epoch: 350, MSE: 0.06110637536408314\n",
            "Epoch: 375, MSE: 0.05797684045342432\n",
            "Epoch: 400, MSE: 0.055538708436774935\n",
            "Epoch: 425, MSE: 0.053587334791136684\n",
            "Epoch: 450, MSE: 0.05199082749692931\n",
            "Epoch: 475, MSE: 0.05066113680997586\n",
            "Epoch: 500, MSE: 0.049537570783459786\n",
            "Epoch: 525, MSE: 0.048577052520919414\n",
            "Epoch: 550, MSE: 0.04774816176038993\n",
            "Epoch: 575, MSE: 0.04702738309280835\n",
            "Epoch: 600, MSE: 0.046396686886841225\n",
            "Epoch: 625, MSE: 0.045841938648387134\n",
            "Epoch: 650, MSE: 0.04535183474420115\n",
            "Epoch: 675, MSE: 0.044917178008453414\n",
            "Epoch: 700, MSE: 0.044530375581638804\n",
            "Epoch: 725, MSE: 0.044185083684275324\n",
            "Epoch: 750, MSE: 0.04387595069274307\n",
            "Epoch: 775, MSE: 0.04359842690648664\n",
            "Epoch: 800, MSE: 0.043348620338746084\n",
            "Epoch: 825, MSE: 0.04312318491868484\n",
            "Epoch: 850, MSE: 0.04291923204805666\n",
            "Epoch: 875, MSE: 0.042734259401618034\n",
            "Epoch: 900, MSE: 0.04256609277298275\n",
            "Epoch: 925, MSE: 0.0424128380179253\n",
            "Epoch: 950, MSE: 0.04227284097374603\n",
            "Epoch: 975, MSE: 0.042144653788492054\n",
            "Epoch: 1000, MSE: 0.04202700647434527\n",
            "Epoch: 1025, MSE: 0.04191878276661633\n",
            "Epoch: 1050, MSE: 0.041818999562290377\n",
            "Epoch: 1075, MSE: 0.04172678935457168\n",
            "Epoch: 1100, MSE: 0.04164138518808797\n",
            "Epoch: 1125, MSE: 0.04156210774348709\n",
            "Epoch: 1150, MSE: 0.04148835422677128\n",
            "Epoch: 1175, MSE: 0.04141958879233328\n",
            "Epoch: 1200, MSE: 0.04135533427236086\n",
            "Epoch: 1225, MSE: 0.04129516502124161\n",
            "Epoch: 1250, MSE: 0.04123870071341309\n",
            "Epoch: 1275, MSE: 0.04118560095795224\n",
            "Epoch: 1300, MSE: 0.041135560613989514\n",
            "Epoch: 1325, MSE: 0.0410883057084961\n",
            "Epoch: 1350, MSE: 0.041043589872681016\n",
            "Epoch: 1375, MSE: 0.041001191225625906\n",
            "Epoch: 1400, MSE: 0.04096090964425263\n",
            "Epoch: 1425, MSE: 0.040922564367571884\n",
            "Epoch: 1450, MSE: 0.04088599189065693\n",
            "Epoch: 1475, MSE: 0.04085104411016047\n",
            "Epoch: 1500, MSE: 0.04081758668858093\n",
            "Epoch: 1525, MSE: 0.04078549760909403\n",
            "Epoch: 1550, MSE: 0.040754665896670976\n",
            "Epoch: 1575, MSE: 0.0407249904845447\n",
            "Epoch: 1600, MSE: 0.040696379207933786\n",
            "Epoch: 1625, MSE: 0.04066874790937272\n",
            "Epoch: 1650, MSE: 0.040642019642080966\n",
            "Epoch: 1675, MSE: 0.04061612395959239\n",
            "Epoch: 1700, MSE: 0.04059099628140689\n",
            "Epoch: 1725, MSE: 0.04056657732574306\n",
            "Epoch: 1750, MSE: 0.04054281260161362\n",
            "Epoch: 1775, MSE: 0.04051965195342442\n",
            "Epoch: 1800, MSE: 0.0404970491521501\n",
            "Epoch: 1825, MSE: 0.04047496152787315\n",
            "Epoch: 1850, MSE: 0.04045334963911046\n",
            "Epoch: 1875, MSE: 0.04043217697490571\n",
            "Epoch: 1900, MSE: 0.04041140968614674\n",
            "Epoch: 1925, MSE: 0.04039101634298816\n",
            "Epoch: 1950, MSE: 0.04037096771562359\n",
            "Epoch: 1975, MSE: 0.040351236575974794\n",
            "Epoch: 2000, MSE: 0.04033179751814189\n",
            "Epoch: 2025, MSE: 0.04031262679570837\n",
            "Epoch: 2050, MSE: 0.04029370217420671\n",
            "Epoch: 2075, MSE: 0.04027500279724377\n",
            "Epoch: 2100, MSE: 0.04025650906494913\n",
            "Epoch: 2125, MSE: 0.040238202523558024\n",
            "Epoch: 2150, MSE: 0.04022006576507217\n",
            "Epoch: 2175, MSE: 0.04020208233605258\n",
            "Epoch: 2200, MSE: 0.04018423665470353\n",
            "Epoch: 2225, MSE: 0.04016651393549517\n",
            "Epoch: 2250, MSE: 0.04014890012065051\n",
            "Epoch: 2275, MSE: 0.040131381817893046\n",
            "Epoch: 2300, MSE: 0.04011394624391457\n",
            "Epoch: 2325, MSE: 0.04009658117307563\n",
            "Epoch: 2350, MSE: 0.04007927489089729\n",
            "Epoch: 2375, MSE: 0.040062016151949896\n",
            "Epoch: 2400, MSE: 0.04004479414177654\n",
            "Epoch: 2425, MSE: 0.04002759844252327\n",
            "Epoch: 2450, MSE: 0.04001041900197584\n",
            "Epoch: 2475, MSE: 0.03999324610572511\n",
            "Epoch: 2500, MSE: 0.03997607035220641\n",
            "Epoch: 2525, MSE: 0.039958882630373116\n",
            "Epoch: 2550, MSE: 0.03994167409977971\n",
            "Epoch: 2575, MSE: 0.039924436172861906\n",
            "Epoch: 2600, MSE: 0.03990716049921136\n",
            "Epoch: 2625, MSE: 0.039889838951650075\n",
            "Epoch: 2650, MSE: 0.03987246361391461\n",
            "Epoch: 2675, MSE: 0.03985502676976867\n",
            "Epoch: 2700, MSE: 0.03983752089336026\n",
            "Epoch: 2725, MSE: 0.03981993864065079\n",
            "Epoch: 2750, MSE: 0.03980227284173796\n",
            "Epoch: 2775, MSE: 0.03978451649390328\n",
            "Epoch: 2800, MSE: 0.03976666275521111\n",
            "Epoch: 2825, MSE: 0.039748704938498254\n",
            "Epoch: 2850, MSE: 0.0397306365055847\n",
            "Epoch: 2875, MSE: 0.039712451061550344\n",
            "Epoch: 2900, MSE: 0.03969414234892455\n",
            "Epoch: 2925, MSE: 0.03967570424164007\n",
            "Epoch: 2950, MSE: 0.039657130738613926\n",
            "Epoch: 2975, MSE: 0.039638415956825504\n",
            "Epoch: 3000, MSE: 0.03961955412377544\n",
            "Epoch: 3025, MSE: 0.03960053956921729\n",
            "Epoch: 3050, MSE: 0.03958136671607295\n",
            "Epoch: 3075, MSE: 0.03956203007045228\n",
            "Epoch: 3100, MSE: 0.03954252421072111\n",
            "Epoch: 3125, MSE: 0.03952284377556814\n",
            "Epoch: 3150, MSE: 0.03950298345105003\n",
            "Epoch: 3175, MSE: 0.03948293795660367\n",
            "Epoch: 3200, MSE: 0.039462702030034096\n",
            "Epoch: 3225, MSE: 0.0394422704115041\n",
            "Epoch: 3250, MSE: 0.0394216378265671\n",
            "Epoch: 3275, MSE: 0.03940079896829692\n",
            "Epoch: 3300, MSE: 0.03937974847858481\n",
            "Epoch: 3325, MSE: 0.03935848092867917\n",
            "Epoch: 3350, MSE: 0.0393369907990585\n",
            "Epoch: 3375, MSE: 0.0393152724587274\n",
            "Epoch: 3400, MSE: 0.039293320144032425\n",
            "Epoch: 3425, MSE: 0.03927112793709787\n",
            "Epoch: 3450, MSE: 0.03924868974397248\n",
            "Epoch: 3475, MSE: 0.039225999272583995\n",
            "Epoch: 3500, MSE: 0.03920305001058173\n",
            "Epoch: 3525, MSE: 0.039179835203149896\n",
            "Epoch: 3550, MSE: 0.03915634783085669\n",
            "Epoch: 3575, MSE: 0.03913258058759641\n",
            "Epoch: 3600, MSE: 0.03910852585867081\n",
            "Epoch: 3625, MSE: 0.039084175699041115\n",
            "Epoch: 3650, MSE: 0.03905952181177237\n",
            "Epoch: 3675, MSE: 0.039034555526675195\n",
            "Epoch: 3700, MSE: 0.0390092677791429\n",
            "Epoch: 3725, MSE: 0.038983649089165705\n",
            "Epoch: 3750, MSE: 0.03895768954049785\n",
            "Epoch: 3775, MSE: 0.03893137875994191\n",
            "Epoch: 3800, MSE: 0.0389047058967054\n",
            "Epoch: 3825, MSE: 0.0388776596017843\n",
            "Epoch: 3850, MSE: 0.03885022800731651\n",
            "Epoch: 3875, MSE: 0.03882239870584932\n",
            "Epoch: 3900, MSE: 0.03879415872946474\n",
            "Epoch: 3925, MSE: 0.03876549452870158\n",
            "Epoch: 3950, MSE: 0.03873639195122087\n",
            "Epoch: 3975, MSE: 0.0387068362201597\n",
            "Epoch: 4000, MSE: 0.03867681191212457\n",
            "Epoch: 4025, MSE: 0.03864630293478523\n",
            "Epoch: 4050, MSE: 0.03861529250402857\n",
            "Epoch: 4075, MSE: 0.03858376312064813\n",
            "Epoch: 4100, MSE: 0.03855169654655082\n",
            "Epoch: 4125, MSE: 0.03851907378047449\n",
            "Epoch: 4150, MSE: 0.0384858750332178\n",
            "Epoch: 4175, MSE: 0.038452079702404524\n",
            "Epoch: 4200, MSE: 0.03841766634680746\n",
            "Epoch: 4225, MSE: 0.03838261266028182\n",
            "Epoch: 4250, MSE: 0.03834689544537089\n",
            "Epoch: 4275, MSE: 0.038310490586661076\n",
            "Epoch: 4300, MSE: 0.03827337302398691\n",
            "Epoch: 4325, MSE: 0.038235516725607495\n",
            "Epoch: 4350, MSE: 0.03819689466149396\n",
            "Epoch: 4375, MSE: 0.03815747877689539\n",
            "Epoch: 4400, MSE: 0.03811723996637632\n",
            "Epoch: 4425, MSE: 0.03807614804854484\n",
            "Epoch: 4450, MSE: 0.03803417174172399\n",
            "Epoch: 4475, MSE: 0.03799127864084804\n",
            "Epoch: 4500, MSE: 0.03794743519590513\n",
            "Epoch: 4525, MSE: 0.037902606692278774\n",
            "Epoch: 4550, MSE: 0.03785675723338614\n",
            "Epoch: 4575, MSE: 0.03780984972604973\n",
            "Epoch: 4600, MSE: 0.03776184586908628\n",
            "Epoch: 4625, MSE: 0.03771270614563856\n",
            "Epoch: 4650, MSE: 0.03766238981982745\n",
            "Epoch: 4675, MSE: 0.037610854938351826\n",
            "Epoch: 4700, MSE: 0.037558058337708464\n",
            "Epoch: 4725, MSE: 0.03750395565776272\n",
            "Epoch: 4750, MSE: 0.037448501362440635\n",
            "Epoch: 4775, MSE: 0.03739164876837297\n",
            "Epoch: 4800, MSE: 0.037333350082354916\n",
            "Epoch: 4825, MSE: 0.037273556448537214\n",
            "Epoch: 4850, MSE: 0.0372122180062928\n",
            "Epoch: 4875, MSE: 0.03714928395973698\n",
            "Epoch: 4900, MSE: 0.03708470265989309\n",
            "Epoch: 4925, MSE: 0.037018421700507634\n",
            "Epoch: 4950, MSE: 0.036950388028510965\n",
            "Epoch: 4975, MSE: 0.036880548070095255\n",
            "Epoch: 5000, MSE: 0.03680884787334233\n",
            "Epoch: 5025, MSE: 0.03673523326826618\n",
            "Epoch: 5050, MSE: 0.0366596500450522\n",
            "Epoch: 5075, MSE: 0.036582044151151405\n",
            "Epoch: 5100, MSE: 0.036502361907748394\n",
            "Epoch: 5125, MSE: 0.036420550245939064\n",
            "Epoch: 5150, MSE: 0.0363365569627438\n",
            "Epoch: 5175, MSE: 0.03625033099683212\n",
            "Epoch: 5200, MSE: 0.03616182272355544\n",
            "Epoch: 5225, MSE: 0.03607098426855723\n",
            "Epoch: 5250, MSE: 0.03597776983889048\n",
            "Epoch: 5275, MSE: 0.03588213607017807\n",
            "Epoch: 5300, MSE: 0.035784042387949515\n",
            "Epoch: 5325, MSE: 0.03568345138086023\n",
            "Epoch: 5350, MSE: 0.03558032918305347\n",
            "Epoch: 5375, MSE: 0.03547464586248956\n",
            "Epoch: 5400, MSE: 0.03536637581162571\n",
            "Epoch: 5425, MSE: 0.035255498136419615\n",
            "Epoch: 5450, MSE: 0.035141997039249404\n",
            "Epoch: 5475, MSE: 0.035025862191011406\n",
            "Epoch: 5500, MSE: 0.034907089087389764\n",
            "Epoch: 5525, MSE: 0.03478567938410493\n",
            "Epoch: 5550, MSE: 0.03466164120584797\n",
            "Epoch: 5575, MSE: 0.03453498942361916\n",
            "Epoch: 5600, MSE: 0.03440574589530704\n",
            "Epoch: 5625, MSE: 0.03427393966459383\n",
            "Epoch: 5650, MSE: 0.03413960711363468\n",
            "Epoch: 5675, MSE: 0.0340027920654603\n",
            "Epoch: 5700, MSE: 0.03386354583265839\n",
            "Epoch: 5725, MSE: 0.03372192720962009\n",
            "Epoch: 5750, MSE: 0.03357800240645275\n",
            "Epoch: 5775, MSE: 0.03343184492356062\n",
            "Epoch: 5800, MSE: 0.03328353536684538\n",
            "Epoch: 5825, MSE: 0.03313316120446194\n",
            "Epoch: 5850, MSE: 0.03298081646704683\n",
            "Epoch: 5875, MSE: 0.03282660139429473\n",
            "Epoch: 5900, MSE: 0.03267062203165969\n",
            "Epoch: 5925, MSE: 0.032512989781780244\n",
            "Epoch: 5950, MSE: 0.03235382091593805\n",
            "Epoch: 5975, MSE: 0.03219323605145725\n",
            "Epoch: 6000, MSE: 0.03203135960138921\n",
            "Epoch: 6025, MSE: 0.03186831920314059\n",
            "Epoch: 6050, MSE: 0.03170424513283047\n",
            "Epoch: 6075, MSE: 0.03153926971216538\n",
            "Epoch: 6100, MSE: 0.03137352671445999\n",
            "Epoch: 6125, MSE: 0.03120715077614079\n",
            "Epoch: 6150, MSE: 0.03104027681966828\n",
            "Epoch: 6175, MSE: 0.03087303949330011\n",
            "Epoch: 6200, MSE: 0.030705572632540496\n",
            "Epoch: 6225, MSE: 0.030538008747481783\n",
            "Epoch: 6250, MSE: 0.030370478539569066\n",
            "Epoch: 6275, MSE: 0.03020311045064429\n",
            "Epoch: 6300, MSE: 0.030036030246444894\n",
            "Epoch: 6325, MSE: 0.02986936063608676\n",
            "Epoch: 6350, MSE: 0.02970322092845128\n",
            "Epoch: 6375, MSE: 0.029537726725831277\n",
            "Epoch: 6400, MSE: 0.029372989654696605\n",
            "Epoch: 6425, MSE: 0.029209117132989525\n",
            "Epoch: 6450, MSE: 0.02904621217299436\n",
            "Epoch: 6475, MSE: 0.028884373218509406\n",
            "Epoch: 6500, MSE: 0.028723694014802112\n",
            "Epoch: 6525, MSE: 0.028564263509636204\n",
            "Epoch: 6550, MSE: 0.028406165783526203\n",
            "Epoch: 6575, MSE: 0.02824948000727707\n",
            "Epoch: 6600, MSE: 0.028094280424826163\n",
            "Epoch: 6625, MSE: 0.027940636359384274\n",
            "Epoch: 6650, MSE: 0.027788612240890367\n",
            "Epoch: 6675, MSE: 0.027638267652833826\n",
            "Epoch: 6700, MSE: 0.027489657396554387\n",
            "Epoch: 6725, MSE: 0.027342831571198753\n",
            "Epoch: 6750, MSE: 0.027197835667599257\n",
            "Epoch: 6775, MSE: 0.02705471067442063\n",
            "Epoch: 6800, MSE: 0.0269134931950165\n",
            "Epoch: 6825, MSE: 0.026774215573529925\n",
            "Epoch: 6850, MSE: 0.02663690602886399\n",
            "Epoch: 6875, MSE: 0.026501588795238683\n",
            "Epoch: 6900, MSE: 0.026368284268146316\n",
            "Epoch: 6925, MSE: 0.026237009154593413\n",
            "Epoch: 6950, MSE: 0.02610777662661153\n",
            "Epoch: 6975, MSE: 0.025980596477089883\n",
            "Epoch: 7000, MSE: 0.025855475277065387\n",
            "Epoch: 7025, MSE: 0.025732416533671743\n",
            "Epoch: 7050, MSE: 0.02561142084802403\n",
            "Epoch: 7075, MSE: 0.02549248607237485\n",
            "Epoch: 7100, MSE: 0.025375607465942963\n",
            "Epoch: 7125, MSE: 0.025260777848872977\n",
            "Epoch: 7150, MSE: 0.025147987753839363\n",
            "Epoch: 7175, MSE: 0.025037225574860454\n",
            "Epoch: 7200, MSE: 0.024928477712938827\n",
            "Epoch: 7225, MSE: 0.024821728718188604\n",
            "Epoch: 7250, MSE: 0.024716961428156884\n",
            "Epoch: 7275, MSE: 0.024614157102086053\n",
            "Epoch: 7300, MSE: 0.024513295550903962\n",
            "Epoch: 7325, MSE: 0.024414355262764472\n",
            "Epoch: 7350, MSE: 0.02431731352399624\n",
            "Epoch: 7375, MSE: 0.024222146535348904\n",
            "Epoch: 7400, MSE: 0.02412882952345573\n",
            "Epoch: 7425, MSE: 0.024037336847460324\n",
            "Epoch: 7450, MSE: 0.023947642100778526\n",
            "Epoch: 7475, MSE: 0.023859718207992972\n",
            "Epoch: 7500, MSE: 0.023773537516897342\n",
            "Epoch: 7525, MSE: 0.023689071885728056\n",
            "Epoch: 7550, MSE: 0.023606292765637603\n",
            "Epoch: 7575, MSE: 0.023525171278482956\n",
            "Epoch: 7600, MSE: 0.023445678290012477\n",
            "Epoch: 7625, MSE: 0.02336778447855182\n",
            "Epoch: 7650, MSE: 0.023291460399297786\n",
            "Epoch: 7675, MSE: 0.02321667654433902\n",
            "Epoch: 7700, MSE: 0.023143403398532433\n",
            "Epoch: 7725, MSE: 0.023071611491369323\n",
            "Epoch: 7750, MSE: 0.0230012714449719\n",
            "Epoch: 7775, MSE: 0.022932354018364715\n",
            "Epoch: 7800, MSE: 0.022864830148169743\n",
            "Epoch: 7825, MSE: 0.0227986709858753\n",
            "Epoch: 7850, MSE: 0.02273384793183219\n",
            "Epoch: 7875, MSE: 0.022670332666126617\n",
            "Epoch: 7900, MSE: 0.022608097176486795\n",
            "Epoch: 7925, MSE: 0.02254711378337005\n",
            "Epoch: 7950, MSE: 0.022487355162383555\n",
            "Epoch: 7975, MSE: 0.022428794364183775\n",
            "Epoch: 8000, MSE: 0.022371404832001365\n",
            "Epoch: 8025, MSE: 0.02231516041693207\n",
            "Epoch: 8050, MSE: 0.022260035391130563\n",
            "Epoch: 8075, MSE: 0.022206004459043815\n",
            "Epoch: 8100, MSE: 0.022153042766811504\n",
            "Epoch: 8125, MSE: 0.022101125909959267\n",
            "Epoch: 8150, MSE: 0.022050229939506595\n",
            "Epoch: 8175, MSE: 0.022000331366603686\n",
            "Epoch: 8200, MSE: 0.02195140716580955\n",
            "Epoch: 8225, MSE: 0.021903434777116742\n",
            "Epoch: 8250, MSE: 0.021856392106824035\n",
            "Epoch: 8275, MSE: 0.021810257527353383\n",
            "Epoch: 8300, MSE: 0.0217650098761021\n",
            "Epoch: 8325, MSE: 0.021720628453416897\n",
            "Epoch: 8350, MSE: 0.021677093019771037\n",
            "Epoch: 8375, MSE: 0.021634383792221882\n",
            "Epoch: 8400, MSE: 0.02159248144022091\n",
            "Epoch: 8425, MSE: 0.02155136708084364\n",
            "Epoch: 8450, MSE: 0.021511022273504116\n",
            "Epoch: 8475, MSE: 0.021471429014211618\n",
            "Epoch: 8500, MSE: 0.021432569729426802\n",
            "Epoch: 8525, MSE: 0.021394427269567275\n",
            "Epoch: 8550, MSE: 0.021356984902211114\n",
            "Epoch: 8575, MSE: 0.021320226305042655\n",
            "Epoch: 8600, MSE: 0.021284135558580927\n",
            "Epoch: 8625, MSE: 0.021248697138728973\n",
            "Epoch: 8650, MSE: 0.02121389590917896\n",
            "Epoch: 8675, MSE: 0.021179717113704123\n",
            "Epoch: 8700, MSE: 0.021146146368367466\n",
            "Epoch: 8725, MSE: 0.021113169653673873\n",
            "Epoch: 8750, MSE: 0.02108077330668905\n",
            "Epoch: 8775, MSE: 0.02104894401314812\n",
            "Epoch: 8800, MSE: 0.02101766879957406\n",
            "Epoch: 8825, MSE: 0.020986935025422444\n",
            "Epoch: 8850, MSE: 0.020956730375270863\n",
            "Epoch: 8875, MSE: 0.02092704285106522\n",
            "Epoch: 8900, MSE: 0.02089786076443718\n",
            "Epoch: 8925, MSE: 0.02086917272910441\n",
            "Epoch: 8950, MSE: 0.020840967653362116\n",
            "Epoch: 8975, MSE: 0.020813234732676447\n",
            "Epoch: 9000, MSE: 0.020785963442386545\n",
            "Epoch: 9025, MSE: 0.02075914353052159\n",
            "Epoch: 9050, MSE: 0.02073276501073942\n",
            "Epoch: 9075, MSE: 0.020706818155390657\n",
            "Epoch: 9100, MSE: 0.020681293488712695\n",
            "Epoch: 9125, MSE: 0.020656181780156407\n",
            "Epoch: 9150, MSE: 0.02063147403784858\n",
            "Epoch: 9175, MSE: 0.020607161502191638\n",
            "Epoch: 9200, MSE: 0.020583235639601634\n",
            "Epoch: 9225, MSE: 0.02055968813638654\n",
            "Epoch: 9250, MSE: 0.02053651089276379\n",
            "Epoch: 9275, MSE: 0.020513696017018194\n",
            "Epoch: 9300, MSE: 0.02049123581979897\n",
            "Epoch: 9325, MSE: 0.020469122808556017\n",
            "Epoch: 9350, MSE: 0.02044734968211378\n",
            "Epoch: 9375, MSE: 0.020425909325381505\n",
            "Epoch: 9400, MSE: 0.020404794804199176\n",
            "Epoch: 9425, MSE: 0.020383999360316218\n",
            "Epoch: 9450, MSE: 0.02036351640650222\n",
            "Epoch: 9475, MSE: 0.020343339521786814\n",
            "Epoch: 9500, MSE: 0.020323462446827735\n",
            "Epoch: 9525, MSE: 0.02030387907940321\n",
            "Epoch: 9550, MSE: 0.020284583470027723\n",
            "Epoch: 9575, MSE: 0.020265569817688654\n",
            "Epoch: 9600, MSE: 0.020246832465700155\n",
            "Epoch: 9625, MSE: 0.020228365897673354\n",
            "Epoch: 9650, MSE: 0.020210164733599163\n",
            "Epoch: 9675, MSE: 0.020192223726041725\n",
            "Epoch: 9700, MSE: 0.020174537756440136\n",
            "Epoch: 9725, MSE: 0.02015710183151475\n",
            "Epoch: 9750, MSE: 0.02013991107977709\n",
            "Epoch: 9775, MSE: 0.020122960748139514\n",
            "Epoch: 9800, MSE: 0.020106246198622897\n",
            "Epoch: 9825, MSE: 0.020089762905159382\n",
            "Epoch: 9850, MSE: 0.020073506450487742\n",
            "Epoch: 9875, MSE: 0.020057472523139233\n",
            "Epoch: 9900, MSE: 0.02004165691451105\n",
            "Epoch: 9925, MSE: 0.020026055516025366\n",
            "Epoch: 9950, MSE: 0.02001066431637135\n",
            "Epoch: 9975, MSE: 0.019995479398828193\n",
            "Epoch: 10000, MSE: 0.019980496938666246\n",
            "Epoch: 10000, MSE: 0.019980496938666246\n",
            "Output: [0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1, 2, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 1, 2, 1]\n",
            "Target: [0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2, 1]\n",
            "Accuracy: 0.9555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_neurons_options = [3, 5, 7]\n",
        "max_epoch_options = [500, 1000, 1500]\n",
        "max_error_options = [0.1, 0.05, 0.01]\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = minmax_scale(iris.data)\n",
        "Y = onehot_enc(iris.target)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = None\n",
        "\n",
        "for hidden_neurons in hidden_neurons_options:\n",
        "    for max_epoch in max_epoch_options:\n",
        "        for max_error in max_error_options:\n",
        "            print(f\"Training dengan hidden_neurons={hidden_neurons}, max_epoch={max_epoch}, max_error={max_error}\")\n",
        "\n",
        "            layer_conf = (4, hidden_neurons, 3)\n",
        "            w, ep, mse = bp_fit(X_train, y_train, layer_conf=layer_conf, max_epoch=max_epoch, max_error=max_error)\n",
        "\n",
        "            predictions = bp_predict(X_val, w)\n",
        "            predictions = onehot_dec(predictions)\n",
        "            y_val_decoded = onehot_dec(y_val)\n",
        "            accuracy = accuracy_score(predictions, y_val_decoded)\n",
        "\n",
        "            print(f\"Akurasi validasi: {accuracy}\")\n",
        "\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                best_params = {'hidden_neurons': hidden_neurons, 'max_epoch': max_epoch, 'max_error': max_error}\n",
        "\n",
        "print(f\"Parameter Terbaik: {best_params}\")\n",
        "print(f\"Akurasi validasi terbaik: {best_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYz_3zSz7FXm",
        "outputId": "14d4a1a9-1442-401d-83bb-59212a417d9f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dengan hidden_neurons=3, max_epoch=500, max_error=0.1\n",
            "Epoch: 100, MSE: 0.19740347109913006\n",
            "Akurasi validasi: 0.9777777777777777\n",
            "Training dengan hidden_neurons=3, max_epoch=500, max_error=0.05\n",
            "Epoch: 100, MSE: 0.19631456450669632\n",
            "Epoch: 200, MSE: 0.0712322341576985\n",
            "Epoch: 300, MSE: 0.05459792229901141\n",
            "Akurasi validasi: 0.9777777777777777\n",
            "Training dengan hidden_neurons=3, max_epoch=500, max_error=0.01\n",
            "Epoch: 100, MSE: 0.19740347109913006\n",
            "Epoch: 200, MSE: 0.07135124444502335\n",
            "Epoch: 300, MSE: 0.05466114541687549\n",
            "Epoch: 400, MSE: 0.04884497131588288\n",
            "Epoch: 500, MSE: 0.04584978664862286\n",
            "Akurasi validasi: 0.9777777777777777\n",
            "Training dengan hidden_neurons=3, max_epoch=1000, max_error=0.1\n",
            "Epoch: 100, MSE: 0.19631456450669632\n",
            "Akurasi validasi: 0.9777777777777777\n",
            "Training dengan hidden_neurons=3, max_epoch=1000, max_error=0.05\n",
            "Epoch: 100, MSE: 0.19740347109913006\n",
            "Epoch: 200, MSE: 0.07135124444502335\n",
            "Epoch: 300, MSE: 0.05466114541687549\n",
            "Akurasi validasi: 0.9777777777777777\n",
            "Training dengan hidden_neurons=3, max_epoch=1000, max_error=0.01\n",
            "Epoch: 100, MSE: 0.19631456450669632\n",
            "Epoch: 200, MSE: 0.0712322341576985\n",
            "Epoch: 300, MSE: 0.05459792229901141\n",
            "Epoch: 400, MSE: 0.04878582540940057\n",
            "Epoch: 500, MSE: 0.04579059931195386\n",
            "Epoch: 600, MSE: 0.044018395866749195\n",
            "Epoch: 700, MSE: 0.04289495032843837\n",
            "Epoch: 800, MSE: 0.042147009589576644\n",
            "Epoch: 900, MSE: 0.04162783187842702\n",
            "Epoch: 1000, MSE: 0.041253525304176406\n",
            "Akurasi validasi: 1.0\n",
            "Training dengan hidden_neurons=3, max_epoch=1500, max_error=0.1\n",
            "Epoch: 100, MSE: 0.19740347109913006\n",
            "Akurasi validasi: 0.9777777777777777\n",
            "Training dengan hidden_neurons=3, max_epoch=1500, max_error=0.05\n",
            "Epoch: 100, MSE: 0.19631456450669632\n",
            "Epoch: 200, MSE: 0.0712322341576985\n",
            "Epoch: 300, MSE: 0.05459792229901141\n",
            "Akurasi validasi: 0.9777777777777777\n",
            "Training dengan hidden_neurons=3, max_epoch=1500, max_error=0.01\n",
            "Epoch: 100, MSE: 0.19740347109913006\n",
            "Epoch: 200, MSE: 0.07135124444502335\n",
            "Epoch: 300, MSE: 0.05466114541687549\n",
            "Epoch: 400, MSE: 0.04884497131588288\n",
            "Epoch: 500, MSE: 0.04584978664862286\n",
            "Epoch: 600, MSE: 0.04407880617365528\n",
            "Epoch: 700, MSE: 0.042956991928257866\n",
            "Epoch: 800, MSE: 0.04221070742956404\n",
            "Epoch: 900, MSE: 0.04169304996711534\n",
            "Epoch: 1000, MSE: 0.041320079834382344\n",
            "Epoch: 1100, MSE: 0.0410417430786082\n",
            "Epoch: 1200, MSE: 0.04082713976950973\n",
            "Epoch: 1300, MSE: 0.040656613980070436\n",
            "Epoch: 1400, MSE: 0.04051732680571617\n",
            "Epoch: 1500, MSE: 0.04040069125817849\n",
            "Akurasi validasi: 1.0\n",
            "Training dengan hidden_neurons=5, max_epoch=500, max_error=0.1\n",
            "Epoch: 100, MSE: 0.22055395702246872\n",
            "Akurasi validasi: 0.6\n",
            "Training dengan hidden_neurons=5, max_epoch=500, max_error=0.05\n",
            "Epoch: 100, MSE: 0.22055395702246872\n",
            "Epoch: 200, MSE: 0.07681687961984963\n",
            "Epoch: 300, MSE: 0.05510923981256214\n",
            "Akurasi validasi: 0.6\n",
            "Training dengan hidden_neurons=5, max_epoch=500, max_error=0.01\n",
            "Epoch: 100, MSE: 0.22055395702246872\n",
            "Epoch: 200, MSE: 0.07681687961984963\n",
            "Epoch: 300, MSE: 0.05510923981256214\n",
            "Epoch: 400, MSE: 0.04838056581131802\n",
            "Epoch: 500, MSE: 0.045117828543726306\n",
            "Akurasi validasi: 0.6\n",
            "Training dengan hidden_neurons=5, max_epoch=1000, max_error=0.1\n",
            "Epoch: 100, MSE: 0.22055395702246872\n",
            "Akurasi validasi: 0.6\n",
            "Training dengan hidden_neurons=5, max_epoch=1000, max_error=0.05\n",
            "Epoch: 100, MSE: 0.22055395702246872\n",
            "Epoch: 200, MSE: 0.07681687961984963\n",
            "Epoch: 300, MSE: 0.05510923981256214\n",
            "Akurasi validasi: 0.6\n",
            "Training dengan hidden_neurons=5, max_epoch=1000, max_error=0.01\n",
            "Epoch: 100, MSE: 0.22055395702246872\n",
            "Epoch: 200, MSE: 0.07681687961984963\n",
            "Epoch: 300, MSE: 0.05510923981256214\n",
            "Epoch: 400, MSE: 0.04838056581131802\n",
            "Epoch: 500, MSE: 0.045117828543726306\n",
            "Epoch: 600, MSE: 0.04324863462350912\n",
            "Epoch: 700, MSE: 0.042088205907144655\n",
            "Epoch: 800, MSE: 0.04132744237202022\n",
            "Epoch: 900, MSE: 0.0408054825424451\n",
            "Epoch: 1000, MSE: 0.040432320833565336\n",
            "Akurasi validasi: 0.6\n",
            "Training dengan hidden_neurons=5, max_epoch=1500, max_error=0.1\n",
            "Epoch: 100, MSE: 0.22055395702246872\n",
            "Akurasi validasi: 0.6\n",
            "Training dengan hidden_neurons=5, max_epoch=1500, max_error=0.05\n",
            "Epoch: 100, MSE: 0.22055395702246872\n",
            "Epoch: 200, MSE: 0.07681687961984963\n",
            "Epoch: 300, MSE: 0.05510923981256214\n",
            "Akurasi validasi: 0.6\n",
            "Training dengan hidden_neurons=5, max_epoch=1500, max_error=0.01\n",
            "Epoch: 100, MSE: 0.22055395702246872\n",
            "Epoch: 200, MSE: 0.07681687961984963\n",
            "Epoch: 300, MSE: 0.05510923981256214\n",
            "Epoch: 400, MSE: 0.04838056581131802\n",
            "Epoch: 500, MSE: 0.045117828543726306\n",
            "Epoch: 600, MSE: 0.04324863462350912\n",
            "Epoch: 700, MSE: 0.042088205907144655\n",
            "Epoch: 800, MSE: 0.04132744237202022\n",
            "Epoch: 900, MSE: 0.0408054825424451\n",
            "Epoch: 1000, MSE: 0.040432320833565336\n",
            "Epoch: 1100, MSE: 0.040155165155790616\n",
            "Epoch: 1200, MSE: 0.0399418857515603\n",
            "Epoch: 1300, MSE: 0.039772301488810634\n",
            "Epoch: 1400, MSE: 0.039633376842118755\n",
            "Epoch: 1500, MSE: 0.039516475983886114\n",
            "Akurasi validasi: 0.6\n",
            "Training dengan hidden_neurons=7, max_epoch=500, max_error=0.1\n",
            "Epoch: 100, MSE: 0.2050701450176025\n",
            "Akurasi validasi: 0.9777777777777777\n",
            "Training dengan hidden_neurons=7, max_epoch=500, max_error=0.05\n",
            "Epoch: 100, MSE: 0.2050701450176025\n",
            "Epoch: 200, MSE: 0.08046519537778334\n",
            "Epoch: 300, MSE: 0.056555795204316146\n",
            "Akurasi validasi: 0.9777777777777777\n",
            "Training dengan hidden_neurons=7, max_epoch=500, max_error=0.01\n",
            "Epoch: 100, MSE: 0.2050701450176025\n",
            "Epoch: 200, MSE: 0.08046519537778334\n",
            "Epoch: 300, MSE: 0.056555795204316146\n",
            "Epoch: 400, MSE: 0.049029059598990725\n",
            "Epoch: 500, MSE: 0.04538649911214216\n",
            "Akurasi validasi: 0.9777777777777777\n",
            "Training dengan hidden_neurons=7, max_epoch=1000, max_error=0.1\n",
            "Epoch: 100, MSE: 0.2050701450176025\n",
            "Akurasi validasi: 0.9777777777777777\n",
            "Training dengan hidden_neurons=7, max_epoch=1000, max_error=0.05\n",
            "Epoch: 100, MSE: 0.2050701450176025\n",
            "Epoch: 200, MSE: 0.08046519537778334\n",
            "Epoch: 300, MSE: 0.056555795204316146\n",
            "Akurasi validasi: 0.9777777777777777\n",
            "Training dengan hidden_neurons=7, max_epoch=1000, max_error=0.01\n",
            "Epoch: 100, MSE: 0.2050701450176025\n",
            "Epoch: 200, MSE: 0.08046519537778334\n",
            "Epoch: 300, MSE: 0.056555795204316146\n",
            "Epoch: 400, MSE: 0.049029059598990725\n",
            "Epoch: 500, MSE: 0.04538649911214216\n",
            "Epoch: 600, MSE: 0.043283187086994086\n",
            "Epoch: 700, MSE: 0.04196145959765864\n",
            "Epoch: 800, MSE: 0.041083115768597196\n",
            "Epoch: 900, MSE: 0.040471662227497186\n",
            "Epoch: 1000, MSE: 0.04002746764156475\n",
            "Akurasi validasi: 1.0\n",
            "Training dengan hidden_neurons=7, max_epoch=1500, max_error=0.1\n",
            "Epoch: 100, MSE: 0.2050701450176025\n",
            "Akurasi validasi: 0.9777777777777777\n",
            "Training dengan hidden_neurons=7, max_epoch=1500, max_error=0.05\n",
            "Epoch: 100, MSE: 0.2050701450176025\n",
            "Epoch: 200, MSE: 0.08046519537778334\n",
            "Epoch: 300, MSE: 0.056555795204316146\n",
            "Akurasi validasi: 0.9777777777777777\n",
            "Training dengan hidden_neurons=7, max_epoch=1500, max_error=0.01\n",
            "Epoch: 100, MSE: 0.2050701450176025\n",
            "Epoch: 200, MSE: 0.08046519537778334\n",
            "Epoch: 300, MSE: 0.056555795204316146\n",
            "Epoch: 400, MSE: 0.049029059598990725\n",
            "Epoch: 500, MSE: 0.04538649911214216\n",
            "Epoch: 600, MSE: 0.043283187086994086\n",
            "Epoch: 700, MSE: 0.04196145959765864\n",
            "Epoch: 800, MSE: 0.041083115768597196\n",
            "Epoch: 900, MSE: 0.040471662227497186\n",
            "Epoch: 1000, MSE: 0.04002746764156475\n",
            "Epoch: 1100, MSE: 0.03969146341898969\n",
            "Epoch: 1200, MSE: 0.0394272881275417\n",
            "Epoch: 1300, MSE: 0.03921182020645306\n",
            "Epoch: 1400, MSE: 0.03902991086018981\n",
            "Epoch: 1500, MSE: 0.03887134341369224\n",
            "Akurasi validasi: 1.0\n",
            "Parameter Terbaik: {'hidden_neurons': 3, 'max_epoch': 1000, 'max_error': 0.01}\n",
            "Akurasi validasi terbaik: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.3, random_state=1)\n",
        "w, ep, mse = bp_fit(X_train, y_train, layer_conf = (4,3,3), learn_rate = .1, max_epoch = 1000, max_error = .01, print_per_epoch = 25)\n",
        "\n",
        "print(f'Epoch: {ep}, MSE: {mse}')\n",
        "\n",
        "predict2 = bp_predict(X_test, w)\n",
        "predict2 = onehot_dec(predict2)\n",
        "y_test = onehot_dec(y_test)\n",
        "accuracy = accuracy_score(predict2, y_test)\n",
        "\n",
        "print('Output:', predict2)\n",
        "print('Target:', y_test)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypn_H4Ws7vg5",
        "outputId": "e024f61b-4a0f-493b-e9fc-875636b31af0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25, MSE: 0.38400588259178264\n",
            "Epoch: 50, MSE: 0.3015244345783775\n",
            "Epoch: 75, MSE: 0.2610489438635036\n",
            "Epoch: 100, MSE: 0.19631456450669632\n",
            "Epoch: 125, MSE: 0.13515114584104024\n",
            "Epoch: 150, MSE: 0.10015545476521427\n",
            "Epoch: 175, MSE: 0.08173256513095625\n",
            "Epoch: 200, MSE: 0.0712322341576985\n",
            "Epoch: 225, MSE: 0.06466815604267687\n",
            "Epoch: 250, MSE: 0.060226671609326925\n",
            "Epoch: 275, MSE: 0.057024195347387535\n",
            "Epoch: 300, MSE: 0.05459792229901141\n",
            "Epoch: 325, MSE: 0.052688748009564\n",
            "Epoch: 350, MSE: 0.051142626862461106\n",
            "Epoch: 375, MSE: 0.04986288408483368\n",
            "Epoch: 400, MSE: 0.04878582540940057\n",
            "Epoch: 425, MSE: 0.047867616003047175\n",
            "Epoch: 450, MSE: 0.04707689616775968\n",
            "Epoch: 475, MSE: 0.04639045462432012\n",
            "Epoch: 500, MSE: 0.04579059931195386\n",
            "Epoch: 525, MSE: 0.045263505206232416\n",
            "Epoch: 550, MSE: 0.04479814272913038\n",
            "Epoch: 575, MSE: 0.04438556127693989\n",
            "Epoch: 600, MSE: 0.044018395866749195\n",
            "Epoch: 625, MSE: 0.0436905176374531\n",
            "Epoch: 650, MSE: 0.043396779501970684\n",
            "Epoch: 675, MSE: 0.04313282637023105\n",
            "Epoch: 700, MSE: 0.04289495032843837\n",
            "Epoch: 725, MSE: 0.04267997791839425\n",
            "Epoch: 750, MSE: 0.04248518089966763\n",
            "Epoch: 775, MSE: 0.04230820458376723\n",
            "Epoch: 800, MSE: 0.042147009589576644\n",
            "Epoch: 825, MSE: 0.04199982403670533\n",
            "Epoch: 850, MSE: 0.041865103983961365\n",
            "Epoch: 875, MSE: 0.04174150046726577\n",
            "Epoch: 900, MSE: 0.04162783187842702\n",
            "Epoch: 925, MSE: 0.041523060706122286\n",
            "Epoch: 950, MSE: 0.04142627386712954\n",
            "Epoch: 975, MSE: 0.04133666601145223\n",
            "Epoch: 1000, MSE: 0.041253525304176406\n",
            "Epoch: 1000, MSE: 0.041253525304176406\n",
            "Output: [0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2, 1]\n",
            "Target: [0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2, 1]\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}